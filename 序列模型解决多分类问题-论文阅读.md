
小错误：
1 论文中采用了2部分的数据集，对这两个部分的数据集解释十分清楚，但是在对数据集进行训练集、验证集和测试集的划分上，没有做任何说明，甚至没有大概的比例说明，这让想要做论文复现的学习者来说不友好。
2
大错误：
1 论文的摘要部分说 在对预测不同标签时，文本不同部分对预测的贡献不同的这一想法，在之前的工作结果中没有被考虑过，这是不正确的，在采用RNN的网络中，因为RNN的特征，不管文本各个部分的贡献问题有没有被提出，实际上模型的原因，都已经或多或少的被实践了的，知识没有过多考虑到这一点。
2 论文的 错误分析部分，是存在较大问题的。该部分实际应该讲的是在实验过程中遇到的错误及对其解决分析过程，而论文中该部分的内容讲解的是以往模型的不足和当前模型效果较好的对比，这可以作为实验结果的一个对比。
3

问题1：各个类别之间是有关联关系的，
问题2：文本的不同部分对预测分类的贡献不同，这是当前存在的模型没有考虑的问题
将多分类问题看做是序列生成模型，解码器结构的序列生成模型
#该序列生成模型由编码器和含注意力机制的解码器组成#
解码器使用LSTM 有序生成标签，给予上一个预测的标签来预测下一个标签
注意力机制的引入来解决问题2

相比较拥有注意力机制的seq2seq模型，本论文中的添加了全局嵌入的序列生成模型，在解码器结构中新加入了转化门，当前预测的y t依赖于之前的预测输出y 1到y t-1，所以作者创新性的添加了转化门来衡量前面错误的预测对当前预测所造成的影响，被称作曝光误差。当前预测的状态获取在上一个隐藏状态和通过转化门的之前所有的输出y来决定，这也是解码模型的创新之处。
在验证在多分类问题在encode-decode模型中使用改进的使用了全局嵌入的解码器是否对模型的结果真正有改进方面，论文中作者通过改变转化门的参数，形成有无全局嵌入以及使用不同参数的全局嵌入的实验对比，通过结果的对比图表，再次证明退出这种创新模型的可行性以及进步性。给我们在今后的科学创新中，提供了验证自己创新结果的思路。
论文中不断验证模型在不同问题参数下的效果，例如为了验证使用使用句子包含标签个数不同时，对模型预测结果的影响，作者使用将数据分为 标签序列长度不同的各个子集（在每个子集中，句子标签序列长度相等），然后在不同的测试集上面，验证模型效果，形成实验结果的对比。
